{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6b89d4",
   "metadata": {},
   "source": [
    "# Utilizing Agents + RAG to Generate Research Ideas\n",
    "### By: Bradley Sides\n",
    "\n",
    "**Steps:**\n",
    "1. Author inputs their 3(?) most recent papers.\n",
    "2. Related works are located using RAG with sentence embeddings.\n",
    "3. With special consideration placed on the author's own papers, augmented with background context from the related works in addition to the model's own knowledge, generate a \"baseline\" research idea for the author.\n",
    "4. Utilize harsh reviewing agents to assess the idea based on multiple criteria.\n",
    "    \n",
    "    a. Novelty agent checks that the idea is sufficiently different from already researched topics. Provides detailed feedback as well as a score.\n",
    "    \n",
    "    b. Fundability/Impact agent checks that the idea is both competitive for grants and focused on an important topic rather than simply something obscure. Provdes detailed feedback as well as a score.\n",
    "5. If score minimums are not met, return to idea generating agent with feedback from both reviewing agents to improve upon the idea, iterate until passing.\n",
    "6. Once score minimums are met, the idea is finalized.\n",
    "\n",
    "\n",
    "**Models Used:**\n",
    "\n",
    "   LLM: Llama 3 70B 8192\n",
    "\n",
    "   Sentence Encoder: sentence-transformers all-MiniLM-L6-v2\n",
    "\n",
    "   Tokenizer: GPT2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23edf0d1",
   "metadata": {},
   "source": [
    "## Load packages, models, environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c3dfa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.dataset as ds\n",
    "import glob\n",
    "from transformers import GPT2Tokenizer\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "GROQ_API_KEY = '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'\n",
    "TAVILY_API_KEY = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43106a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Master DataFrame, pre-cleaned and organized\n",
    "df = pd.read_parquet('compressed_fulldata.parquet')\n",
    "\n",
    "# Sentence Encoder\n",
    "sent_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Language Model: LLama 3\n",
    "    # Num Parameters: 70B\n",
    "    # Context Windoow: 8192\n",
    "GROQ_LLM = ChatGroq(\n",
    "            model=\"llama3-70b-8192\",\n",
    "            groq_api_key=GROQ_API_KEY\n",
    "        )\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45469352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys and OS settings for Langchain\n",
    "#os.environ['LANGCHAIN TRACING V2'] = 'true'\n",
    "#os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "#os.environ['LANGCHAIN API KEY'] = 'ls__cb6a134591764951b016859dde32b411'\n",
    "#!pip -q install langchain-groq duckduckgo-search\n",
    "#!pip -q install -U langchain_community tiktoken langchainhub\n",
    "#!pip -q install -U langchain langgraph tavily-python\n",
    "#!pip show langgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2edd4c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>pmid</th>\n",
       "      <th>concepts</th>\n",
       "      <th>author</th>\n",
       "      <th>num_citations</th>\n",
       "      <th>related_works</th>\n",
       "      <th>cited_by_api_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Treatment of Alcohol Withdrawal Syndrome</td>\n",
       "      <td>Treatment of the alcohol withdrawal syndrome i...</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>7912939</td>\n",
       "      <td>[Alcohol withdrawal syndrome, Medicine, Rehabi...</td>\n",
       "      <td>[Vural Özdemir]</td>\n",
       "      <td>18</td>\n",
       "      <td>[https://openalex.org/W4388336948, https://ope...</td>\n",
       "      <td>https://api.openalex.org/works?filter=cites:W2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  \\\n",
       "0  Treatment of Alcohol Withdrawal Syndrome   \n",
       "\n",
       "                                            abstract publication_date  \\\n",
       "0  Treatment of the alcohol withdrawal syndrome i...       1994-01-01   \n",
       "\n",
       "      pmid                                           concepts  \\\n",
       "0  7912939  [Alcohol withdrawal syndrome, Medicine, Rehabi...   \n",
       "\n",
       "            author  num_citations  \\\n",
       "0  [Vural Özdemir]             18   \n",
       "\n",
       "                                       related_works  \\\n",
       "0  [https://openalex.org/W4388336948, https://ope...   \n",
       "\n",
       "                                    cited_by_api_url  \n",
       "0  https://api.openalex.org/works?filter=cites:W2...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e6db4c",
   "metadata": {},
   "source": [
    "## Implement a simple RAG system using sentence embeddings to find the N most similar papers to each paper the author submits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf7db43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50dd9365a5fa418ab30c4234c34c610e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5790 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185275, 384)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TODO: Implement RAG to get \n",
    "    1. Related works (HyDE/Decomposition/RAG Fusion)\n",
    "    2. Top (3?) citations from each paper\n",
    "'''\n",
    "# create sentence embeddings\n",
    "def embed_sentences():\n",
    "    embed = sent_model.encode(df['abstract'].tolist(), show_progress_bar = True)\n",
    "    print(np.array(embed).shape)\n",
    "    np.save('saved_embeddings.npy', embed) # Optional for saving the embeddings to disk\n",
    "    return embed\n",
    "    \n",
    "# find similar papers based on cosine similarity between sentence embeddings\n",
    "def simple_rag(abstract, emb_list, abstract_df, n):\n",
    "    query_emb = sent_model.encode([abstract])[0]\n",
    "    similarities = cosine_similarity([query_emb], emb_list)[0]\n",
    "    # top = np.argsort(similarities)[-n:][::-1] # Indices of top n most similar papers, excluding the paper itself\n",
    "    # USE THIS IF PASSING IN A PAPER FROM DATASET, OTHER IF \n",
    "    top = np.argsort(similarities)[-n-1:][::-1] \n",
    "    top_papers = abstract_df.iloc[top]\n",
    "    return [(row['title'], row['abstract']) for idx, row in top_papers.iterrows()]\n",
    "\n",
    "# print out original and similar papers\n",
    "def print_similar(sim_papers):\n",
    "    \n",
    "    print(\"ORIGINAL PAPER: \")\n",
    "    print(\"________________________________________________\")\n",
    "    print(\"Title: \" + sim_papers[0][0])\n",
    "    print(\"\")\n",
    "    print(\"Abstract: \" + sim_papers[0][1])\n",
    "    print(\"=========================================================\")\n",
    "    for i in range(len(sim_papers)-1):\n",
    "        print(\"++++++++++++++++++++++++++++++++++\")\n",
    "        print(\"Related title Number \" + str((i+1)))\n",
    "        print(\"++++++++++++++++++++++++++++++++++\")\n",
    "        print(\"Title: \" + sim_papers[i+1][0])\n",
    "        print(\"\")\n",
    "        print(\"Abstract: \" + sim_papers[i+1][1])\n",
    "        print(\"=========================================================\")\n",
    "\n",
    "embed = embed_sentences()\n",
    "#abstract = my_abstracts[0]\n",
    "#n = 2 # Number of papers to pull\n",
    "#sim_papers = simple_rag(abstract, embed, df, n) # First entry is the same paper, drop it\n",
    "#print_similar(sim_papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb5b6fb",
   "metadata": {},
   "source": [
    "## Generate the initial idea focused on author's work and utilizing related works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "87853c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This will serve as the initial idea generator for the agents to work on\n",
    "'''\n",
    "prompt = PromptTemplate(\n",
    "    template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are a research assistant. You are a master at synthesizing information to formulate creative, novel, fundable, and feasible ideas that improve on the previous work that is presented to you.\n",
    "    \n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Conduct a comprehensive analysis of the abstracts and related work provided below and present a well-formulated idea for a new research paper that logically follows the direction of research in my field. \n",
    "    Here are my 3 previous papers, from most to least recent:\n",
    "    My recent papers: \\n\\n {og_papers} \\n\\n\n",
    "    \n",
    "    <|eot_id|>\n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables = [\"og_papers\"]\n",
    ")\n",
    "\n",
    "og_papers = my_data\n",
    "base_idea_gen = prompt | GROQ_LLM | StrOutputParser()\n",
    "#idea = base_idea.invoke({\"og_papers\": og_papers})\n",
    "#print(idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a40b57e",
   "metadata": {},
   "source": [
    "## Introduce Reviewing Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4de9f",
   "metadata": {},
   "source": [
    "### 1: Fundability and Impact Reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1a561a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "REVIEWING AGENT #1: FUNDABILITY AND IMPACT REVIEWER\n",
    "    \n",
    "** Note: Utilizing prompts from researchAgent paper heavily for this, will need to make new ones \n",
    "'''\n",
    "fundability_agent_prompt = PromptTemplate(template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are an AI assistant whose primary goal is to meticulously evaluate the fundability of research ideas based off of the NSF funding criteria in order to aid researchers in refining their approaches based on your evaluations and feedback, thereby amplifying the quality and impact of their scientific contributions.\n",
    "    \\n\\n\n",
    "    You are going to evaluate a research idea for its potential fundability by the NSF. Refer to the target papers to help understand the context of the problem for a more comprehensive assessment.\n",
    "    \n",
    "    The existing studies are: {og_papers}\n",
    "    \n",
    "    Now, proceed with your evaluation approach that should be systematic:\n",
    "        - Start by thoroughly reading the experiment design and its rationale, keeping in mind the context provided by the research problem, scientific method, and existing studies mentioned above.\n",
    "        - Next, generate a review and feedback that should be constructive, helpful, and concise, focusing on the fundability of the experiment.\n",
    "        - Finally, provide a score on a 5-point Likert scale, with 1 being the lowest, please ensuring a discerning and critical evaluation to avoid a tendency towards uniformly high ratings (4-5) unless fully justified:\n",
    "        \n",
    "    Criteria to consider:\n",
    "        - Quality and potential to advance knowledge: Does the project propose high-quality activities that can transform the frontiers of knowledge?\n",
    "        - Contribution to societal goals: How does the project contribute to broader societal goals?\n",
    "        - Metrics for evaluation: Are the metrics for meaningful assessment and evaluation appropriate and well-defined?\n",
    "        - Originality and Creativity: Are the ideas creative, original, or potentially transformative?\n",
    "        - Plan and Rationale: Is the project plan well-reasoned and organized? Does it include mechanisms to assess success?\n",
    "        - Qualifications: How well qualified are the individuals or teams proposing the project?\n",
    "        - Resources: Are adequate resources available to carry out the activities proposed?\n",
    "    \n",
    "    I am going to provide you with the research idea here: {final_idea}\n",
    "    \n",
    "    After your evaluation of the above content, please provide your review, feedback, and rating, in the format of:\n",
    "    Review: \n",
    "    Feedback:\n",
    "    Rating (1-5):\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables = [\"final_idea\", \"og_papers\"]\n",
    ")\n",
    "\n",
    "fundability = fundability_agent_prompt | GROQ_LLM | StrOutputParser()\n",
    "\n",
    "#print(fundability.invoke({\"my_data\": my_data, \"idea\": idea}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132a2209",
   "metadata": {},
   "source": [
    "### 2: Novelty Reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "aa4d53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "REVIEWING AGENT #2: NOVELY REVIEWER\n",
    "\n",
    "Description: This should pull the top N most similar papers to the \"original\" idea and produce a \"novelty\" score, as well as provide feedback.\n",
    "'''\n",
    "novelty_agent_prompt = PromptTemplate(template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are an AI assistant whose primary goal is to meticulously evaluate the novelty of research ideas based off given criteria in order to aid researchers in refining their approaches based on your evaluations and feedback, thereby amplifying the quality and impact of their scientific contributions.\n",
    "    \\n\\n\n",
    "    The process for evaluating an idea for its novelty is outlined as follows:\n",
    "        - Begin by understanding the essence of the proposed idea, focusing particularly on its unique aspects and claims of novelty.\n",
    "        - Compare the idea against a broad spectrum of existing studies, considering both direct and tangential relevance.\n",
    "    \n",
    "    The criteria for novelty assessment are:\n",
    "        - Innovation: Evaluate if the idea introduces any new methodologies, tools, or conceptual frameworks.\n",
    "        - Transformation Potential: Assess whether the idea has the potential to significantly shift current practices or theoretical understanding.\n",
    "        - Differentiation: Examine how distinct the idea is from existing studies. Highlight specific elements that set it apart.\n",
    "        - Feasibility of New Approaches: Consider the practical implementation of the idea, evaluating if the innovative aspects are achievable within the current technological and resource constraints.\n",
    "        - Impact on Existing Knowledge: Determine the potential impact of the idea on stimulating further research or development in its field.\n",
    "        - Interdisciplinary Merit: Consider if the idea brings together diverse fields or disciplines in a way that fosters new directions or insights.\n",
    "\n",
    "        Given the research idea presented here: {final_idea}\n",
    "        Evaluate it against both your own knowledge of related work, as well as the following papers deemed similar through sentence embedding: {most_similar_papers}\n",
    "        Please proceed with your systematic evaluation, and provide a detailed review that includes:\n",
    "            - Your assessment of how the idea meets each novelty criterion.\n",
    "            - Constructive feedback on areas where the idea could be further differentiated or developed.\n",
    "            - A rating on a 5-point scale regarding its overall novelty, where 1 indicates very little novelty and 5 indicates highly novel.\n",
    "\n",
    "    assistant\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables = [\"final_idea\", \"most_similar_papers\"]\n",
    ")\n",
    "novelty = novelty_agent_prompt | GROQ_LLM | StrOutputParser()\n",
    "#most_similar_papers = simple_rag(idea, embed, df, n=10)\n",
    "#print(novelty.invoke({\"idea\": idea, \"most_similar_papers\": most_similar_papers}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a557a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: REWRITING AGENTS:\n",
    "    1. Novelty Rewriter\n",
    "    2. Fundability/Impact Rewriter\n",
    "'''  \n",
    "#Description: These should take feedback from reviewing agents, rewrite according to critiques, and then pass back to the reviewers\n",
    "\n",
    "\n",
    "novelty_analysis_prompt = PromptTemplate(\n",
    "    template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are an expert at evaluating the feedback from reviewers on a research idea based on its novelty and deciding if the idea needs to be updated. \\n\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    This is the research idea: {final_idea} \\n\n",
    "    \n",
    "    this feedback was given on the idea: {novelty_feedback} \\n\n",
    "    \n",
    "    If the score is lower than 4.5, return EXACTLY: rewrite\n",
    "    If the score is 4.5 or higher, return EXACTLY: no_rewrite\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\"\"\",\n",
    "    input_variables= [\"final_idea\", \"novelty_feedback\"]\n",
    ")\n",
    "\n",
    "fundability_analysis_prompt = PromptTemplate(\n",
    "    template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are an expert at evaluating the feedback from reviewers on a research idea based on its fundability and potential and deciding if the idea needs to be updated. \\n\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    This is the research idea: {final_idea} \\n\n",
    "    \n",
    "    this feedback was given on the idea: {fundability_feedback} \\n\n",
    "    \n",
    "    If the score is lower than 4.5, return EXACTLY: rewrite\n",
    "    If the score is 4.5 or higher, return EXACTLY: no_rewrite\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\"\"\",\n",
    "    input_variables= [\"final_idea\", \"fundability_feedback\"]\n",
    ")\n",
    "\n",
    "nov2 = novelty_analysis_prompt | GROQ_LLM | StrOutputParser()\n",
    "fund2 = fundability_analysis_prompt | GROQ_LLM | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f62b05ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_idea_prompt = PromptTemplate(\n",
    "    template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are the final agent in charge of producing novel, fundable, impactful, and feasible research ideas. A research idea has been formulated and reviewed and you are tasked with incorporating the feedback into the idea and potentially augmenting it based on what is recommended.\n",
    "    You must not sacrifice one criteria for the improvement of another, so be careful with your augmentation and utilize the feedback as best you can.\n",
    "    You should produce either an updated version of the idea given to you based on the feedback, or the same idea given to you if augmentation is not necessary. As a baseline, both scores should be above 4.5 Provide justification for any change you make.\n",
    "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    The research idea is: {final_idea}\n",
    "    \n",
    "    \n",
    "    The feedback from the fundability and impact reviewer is: {fundability_feedback}\n",
    "\n",
    "    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables = [\"final_idea\", \"fundability_feedback\"]\n",
    ")\n",
    "\n",
    "rewrite = rewrite_idea_prompt | GROQ_LLM | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92acfa34",
   "metadata": {},
   "source": [
    "## Build the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "80661041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langgraph.graph import END, StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b001b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of the graph\n",
    "    \n",
    "    Attributes: \n",
    "        og_papers: abstract and title of first X papers from main author\n",
    "        sim_papers: abstract and title of Y similar papers to each of og_papers\n",
    "        most_similar_papers: abstract and title of Z similar papers to the IDEA\n",
    "        idea: LLM generated idea\n",
    "        updated_idea: LLM generated idea\n",
    "        novelty_feedback: LLM generated critiques on novelty\n",
    "        fundability_feedback: LLM generated critiques on fundability/impact\n",
    "        num_steps: number of steps taken\n",
    "    \"\"\"\n",
    "    og_papers : str\n",
    "    sim_papers : List[List[str]]\n",
    "    most_similar_papers : List[List[str]]\n",
    "    base_idea : str\n",
    "    final_idea : str\n",
    "    #novelty_feedback : str\n",
    "    fundability_feedback : str\n",
    "    #novelty_analysis: str\n",
    "    fundability_analysis: str\n",
    "    num_steps : int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6ad60a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_docs(state):\n",
    "    '''Get related papers'''\n",
    "    print(\"---FINDING RELATED PAPERS----\")\n",
    "    og_papers = state['og_papers']\n",
    "    sim_papers = state['sim_papers']\n",
    "    num_steps = int(state['num_steps'])\n",
    "    num_steps += 1\n",
    "    for paper in og_papers:\n",
    "        p = simple_rag(paper, embed, df, n=2)\n",
    "        sim_papers.append(p)\n",
    "    print_similar(sim_papers)\n",
    "    return{\"sim_papers\": sim_papers, \"num_steps\": num_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9d4d2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Edit this function AND base_idea to include sim_docs\n",
    "def init_idea(state):\n",
    "    '''Generate initial idea'''\n",
    "    print(\"---GENERATING INITIAL IDEA---\")\n",
    "    og_papers = state['og_papers']\n",
    "    base_idea = state['base_idea']\n",
    "    num_steps = int(state['num_steps'])\n",
    "    num_steps += 1\n",
    "    base_idea = base_idea_gen.invoke({\"og_papers\": og_papers})\n",
    "    final_idea = base_idea # for updating\n",
    "    print(base_idea)\n",
    "    #write_markdown_file(base_idea, \"base_idea\")\n",
    "    return {\"base_idea\": base_idea, \"num_steps\": num_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7bb806d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_fundability(state):\n",
    "    '''Assess fundability and impact of the idea'''\n",
    "    print(\"---ASSESSING FUNDABILITY & IMPACT OF IDEA---\")\n",
    "    og_papers = state['og_papers']\n",
    "    final_idea = state['final_idea']\n",
    "    fundability_feedback = state['fundability_feedback']\n",
    "    num_steps = int(state['num_steps'])\n",
    "    num_steps += 1\n",
    "    \n",
    "    fundability_feedback = fundability.invoke({\"final_idea\": final_idea, \"og_papers\": og_papers})\n",
    "    print(fundability_feedback)\n",
    "    #write_markdown_file(fundability_feedback, \"fundability_feedback\")\n",
    "    return {\"fundability_feedback\": fundability_feedback, \"num_steps\": num_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c95d863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_novelty(state):\n",
    "    '''Assess novelty of idea'''\n",
    "    print(\"---ASSESSING NOVELTY OF IDEA---\")\n",
    "    og_papers = state['og_papers']\n",
    "    final_idea = state['final_idea']\n",
    "    most_similar_papers = state['most_similar_papers']\n",
    "    novelty_feedback = state['novelty_feedback']\n",
    "    num_steps = int(state['num_steps'])\n",
    "    num_steps += 1\n",
    "    \n",
    "    most_similar_papers = simple_rag(final_idea, embed, df, n=8)\n",
    "    novelty_feedback = novelty.invoke({\"final_idea\": final_idea, \"most_similar_papers\": most_similar_papers})\n",
    "    print(novelty_feedback)\n",
    "    #write_markdown_file(novelty_feedback, \"novelty_feedback\")\n",
    "    return {\"novelty_feedback\": novelty_feedback, \"num_steps\": num_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "81d73ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_novelty(state):\n",
    "    '''Decide on update based novelty of idea'''\n",
    "    print(\"---DECIDING ON UPDATE VIA: NOVELTY---\")\n",
    "    novelty_feedback = state['novelty_feedback']\n",
    "    novelty_analysis = state['novelty_analysis']\n",
    "    num_steps = int(state['num_steps'])\n",
    "    num_steps += 1\n",
    "    \n",
    "    novelty_analysis = nov2.invoke({\"final_idea\": final_idea, \"novelty_feedback\": novelty_feedback})\n",
    "    print(novelty_analysis)\n",
    "    #write_markdown_file(novelty_feedback, \"novelty_feedback\")\n",
    "    return {\"novelty_analysis\": novelty_analysis, \"num_steps\": num_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "85ec4e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_fundability(state):\n",
    "    '''Decide on update based fundability of idea'''\n",
    "    print(\"---DECIDING ON UPDATE VIA: FUNDABILITY & IMPACT---\")\n",
    "    final_idea = state['final_idea']\n",
    "    fundability_feedback = state['fundability_feedback']\n",
    "    fundability_analysis = state['fundability_analysis']\n",
    "    \n",
    "    fundability_analysis = fund2.invoke({\"final_idea\": final_idea, \"fundability_feedback\": fundability_feedback})\n",
    "    print(fundability_analysis)\n",
    "    #write_markdown_file(novelty_feedback, \"novelty_feedback\")\n",
    "    updated_state = state.copy()\n",
    "    updated_state['fundability_analysis'] = fundability_analysis\n",
    "    updated_state['num_steps'] = int(state['num_steps']) + 1\n",
    "    return updated_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2a960ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_idea(state):\n",
    "    '''Rewrite the idea based on feedback'''\n",
    "    print(\"---REWRITING IDEA---\")\n",
    "    \n",
    "    final_idea = state['final_idea']\n",
    "    #novelty_feedback = state['novelty_feedback']\n",
    "    fundability_feedback = state['fundability_feedback']\n",
    "    num_steps = int(state['num_steps'])\n",
    "    num_steps += 1\n",
    "    \n",
    "    final_idea = rewrite.invoke({\"final_idea\": final_idea, \"fundability_feedback\": fundability_feedback})\n",
    "    print(final_idea)\n",
    "    return {\"final_idea\": final_idea, \"num_steps\": num_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b2d7affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_more(state):\n",
    "    print(\"NO MORE UPDATES NEEDED\")\n",
    "    final_idea = state['final_idea']\n",
    "    base_idea = state['base_idea']\n",
    "    num_steps = int(state['num_steps'])\n",
    "    num_steps += 1\n",
    "    \n",
    "    #write_markdown_file(base_idea, \"base_idea\")\n",
    "    return {\"final_idea\": final_idea, \"num_steps\": num_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5049a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_printer(state):\n",
    "    \"\"\"Print the state\"\"\"\n",
    "    print(\"---STATE PRINTER---\")\n",
    "    print(f\"base_idea Idea: {state['base_idea']}\\n\")\n",
    "    print(f\"Final Idea: : {state['final_idea']}\\n\")\n",
    "    print(f\"Similar (to my own) Papers: {state['sim_papers']}\\n\")\n",
    "    print(f\"Related (to idea) Papers: {state['most_similar_papers']}\\n\")\n",
    "    print(f\"Fundability Feedback: : {state['fundability_feedback']}\\n\")\n",
    "    #print(f\"Novelty Feedback: {state['novelty_feedback']}\\n\")\n",
    "    print(f\"Num Steps: {state['num_steps']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff50db",
   "metadata": {},
   "source": [
    "### Conditional Edge(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5d770b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Edge\n",
    "def route_to_rewrite(state):\n",
    "    print(\"---ROUTE TO REWRITE---\")\n",
    "    final_idea = state['final_idea']\n",
    "    #novelty_feedback = state['novelty_feedback']\n",
    "    fundability_feedback = state['fundability_feedback']\n",
    "    #novelty_analysis = state['novelty_analysis']\n",
    "    fundability_analysis = state['fundability_analysis']\n",
    "    print(fundability_analysis)\n",
    "    if fundability_analysis == \"rewrite\":\n",
    "        print(\"---ROUTE TO REWRITE---\")\n",
    "        return \"rewrite\"\n",
    "    else:\n",
    "        print(\"---ROUTE TO FINAL---\")\n",
    "        return \"no_rewrite\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c28e542",
   "metadata": {},
   "source": [
    "## Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ae8d655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Nodes:\n",
    "#workflow.add_node(\"find_similar_docs\", find_similar_docs)\n",
    "workflow.add_node(\"init_idea\", init_idea)\n",
    "workflow.add_node(\"assess_fundability\", assess_fundability)\n",
    "#workflow.add_node(\"assess_novelty\", assess_novelty)\n",
    "workflow.add_node(\"analyze_fundability\", analyze_fundability)\n",
    "#workflow.add_node(\"analyze_novelty\", analyze_novelty)\n",
    "workflow.add_node(\"rewrite_idea\", rewrite_idea)\n",
    "workflow.add_node(\"no_more\", no_more)\n",
    "workflow.add_node(\"state_printer\", state_printer)\n",
    "\n",
    "# Edges: \n",
    "workflow.set_entry_point(\"init_idea\")\n",
    "#workflow.add_edge(\"find_similar_docs\", \"init_idea\")\n",
    "workflow.add_edge(\"init_idea\", \"assess_fundability\")\n",
    "workflow.add_edge(\"assess_fundability\", \"analyze_fundability\")\n",
    "#workflow.add_edge(\"assess_novelty\", \"analyze_novelty\")\n",
    "#workflow.add_conditional_edges(\n",
    "    #\"analyze_novelty\", \n",
    "     #route_to_rewrite,\n",
    "    #{\n",
    "         #\"rewrite\": \"rewrite_idea\",\n",
    "         #\"no_rewrite\": \"analyze_fundability\"\n",
    "     #}      \n",
    "#)\n",
    "workflow.add_conditional_edges(\n",
    "    \"analyze_fundability\",\n",
    "    route_to_rewrite,\n",
    "    {\n",
    "        \"rewrite\": \"rewrite_idea\",\n",
    "        \"no_rewrite\": \"no_more\"\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"rewrite_idea\", \"assess_fundability\")\n",
    "workflow.add_edge(\"no_more\", \"state_printer\")\n",
    "workflow.add_edge(\"state_printer\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "793ad008",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8200f033",
   "metadata": {},
   "source": [
    "## Sandbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "684179c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in original papers: 1625\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SANDBOX AREA!!!\n",
    "Practice with authors\n",
    "\"\"\"\n",
    "\n",
    "# Get most recent 5 papers from specific author\n",
    "filter_df = df[df['author'] =='Wei Chen']\n",
    "sorted_df = filter_df.sort_values(by='publication_date', ascending = False)\n",
    "recent_papers = sorted_df.head(5)\n",
    "recent_papers\n",
    "\n",
    "# Format for passing into prompt template\n",
    "my_abstracts = []\n",
    "for i in range(4):\n",
    "    concat = \"TITLE: \" + recent_papers.iloc[i]['title'] + \"\\nABSTRACT: \" + recent_papers.iloc[i]['abstract']\n",
    "    my_abstracts.append(concat)\n",
    "my_data = '\\n\\n'.join(my_abstracts)    \n",
    "token_count = len(tokenizer.tokenize(my_data))\n",
    "print(\"Number of tokens in original papers: \" + str(token_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835864bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = {\"og_papers\": my_data, \"num_steps\":0}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        print(f\"Finished running: {key}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b5ad1000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---GENERATING INITIAL IDEA---\n",
      "After conducting a comprehensive analysis of the abstracts and related work provided, I have formulated a well-formulated idea for a new research paper that logically follows the direction of research in your field. Here's a potential research idea:\n",
      "\n",
      "**Title:** \"Evaluating the Impact of AI-generated Content on the Quality and Integrity of Scientific Publishing: A Large-scale Analysis of Peer-reviewed Articles\"\n",
      "\n",
      "**Research Question:** How do AI-generated content and paraphrased text affect the quality, readability, and credibility of scientific publications, and what are the implications for the scientific community?\n",
      "\n",
      "**Background:** The rapid advancement of AI technology has made text generation tools increasingly accessible, scalable, and effective. However, this poses a significant threat to the credibility of scientific literature, as AI-generated content can be used for plagiarism and manipulation of scientific results. The rise of AI-generated content also raises concerns about the quality and integrity of scientific publishing, particularly in the context of peer review and the dissemination of research findings.\n",
      "\n",
      "**Research Objectives:**\n",
      "\n",
      "1. Develop a large-scale analysis of peer-reviewed articles to identify the prevalence of AI-generated content and paraphrased text in scientific publications.\n",
      "2. Investigate the impact of AI-generated content on the quality, readability, and credibility of scientific publications, using metrics such as clarity, coherence, and accuracy.\n",
      "3. Examine the relationship between AI-generated content and the peer-review process, including the role of author-suggested reviewers and the potential for bias in the review process.\n",
      "4. Explore the implications of AI-generated content for the scientific community, including the potential for misinformation, manipulation, and the erosion of trust in scientific research.\n",
      "\n",
      "**Methodology:**\n",
      "\n",
      "1. Collect a large dataset of peer-reviewed articles from various scientific fields, including but not limited to neuroscience, biology, and computer science.\n",
      "2. Develop and apply natural language processing (NLP) techniques to detect AI-generated content and paraphrased text in the collected dataset.\n",
      "3. Conduct a quantitative analysis of the prevalence and characteristics of AI-generated content in scientific publications, including metrics such as frequency, quality, and readability.\n",
      "4. Investigate the relationship between AI-generated content and the peer-review process, including the role of author-suggested reviewers and the potential for bias in the review process.\n",
      "5. Conduct a qualitative analysis of the implications of AI-generated content for the scientific community, including the potential for misinformation, manipulation, and the erosion of trust in scientific research.\n",
      "\n",
      "**Expected Outcomes:**\n",
      "\n",
      "1. A comprehensive understanding of the prevalence and characteristics of AI-generated content in scientific publications.\n",
      "2. An assessment of the impact of AI-generated content on the quality, readability, and credibility of scientific publications.\n",
      "3. Insights into the relationship between AI-generated content and the peer-review process, including the potential for bias and manipulation.\n",
      "4. Recommendations for the scientific community, publishers, and policymakers to address the challenges and opportunities posed by AI-generated content in scientific publishing.\n",
      "\n",
      "**Significance:** This study will provide valuable insights into the impact of AI-generated content on the quality and integrity of scientific publishing, and will inform strategies for maintaining the credibility and trustworthiness of scientific research in the face of emerging technologies. The findings of this study will have significant implications for the scientific community, publishers, and policymakers, and will contribute to the development of best practices for ensuring the integrity and reliability of scientific research.\n",
      "Finished running: init_idea:\n",
      "---ASSESSING FUNDABILITY & IMPACT OF IDEA---\n",
      "Since you didn't provide a specific research idea, I'll assume you want me to evaluate the four papers provided as a potential research direction. Here's my evaluation:\n",
      "\n",
      "**Review:**\n",
      "The collection of papers provided touches on various aspects of scientific communication, including peer review, figure accessibility, resource longevity, and plagiarism detection. While each paper addresses a specific issue, they collectively highlight the importance of ensuring the integrity and accessibility of scientific knowledge.\n",
      "\n",
      "**Feedback:**\n",
      "To increase fundability, consider integrating these individual studies into a comprehensive project that tackles the broader issue of scientific communication and knowledge dissemination. This could involve developing a framework that combines AI-driven tools for figure analysis, resource longevity prediction, and plagiarism detection. Additionally, exploring the role of peer review in ensuring the quality of scientific publications could strengthen the project's impact. To further improve the proposal, consider:\n",
      "\n",
      "1. Clearly defining the project's objectives and expected outcomes.\n",
      "2. Developing a more detailed plan for integrating the various components into a cohesive system.\n",
      "3. Providing a stronger justification for the project's potential to advance knowledge and contribute to broader societal goals.\n",
      "\n",
      "**Rating: 3**\n",
      "While the individual papers demonstrate potential, the lack of a clear, overarching research direction and a well-defined plan for integration and implementation hinders the proposal's fundability. Strengthening the project's objectives, methodology, and expected outcomes could improve its competitiveness.\n",
      "Finished running: assess_fundability:\n",
      "---DECIDING ON UPDATE VIA: FUNDABILITY & IMPACT---\n",
      "rewrite\n",
      "---ROUTE TO REWRITE---\n",
      "rewrite\n",
      "---ROUTE TO REWRITE---\n",
      "Finished running: analyze_fundability:\n",
      "---REWRITING IDEA---\n",
      "Based on the feedback, I propose the following revised research idea:\n",
      "\n",
      "**Title:** Integrating AI-driven Tools for Ensuring the Integrity and Accessibility of Scientific Knowledge\n",
      "\n",
      "**Research Idea:**\n",
      "\n",
      "This project aims to develop a comprehensive framework that combines AI-driven tools for figure analysis, resource longevity prediction, and plagiarism detection to ensure the integrity and accessibility of scientific knowledge. The framework will integrate the following components:\n",
      "\n",
      "1. **AI-driven figure analysis**: Developing a tool that uses machine learning algorithms to analyze and improve the accessibility of figures in scientific publications.\n",
      "2. **Resource longevity prediction**: Creating a predictive model that forecasts the longevity of online resources cited in scientific publications, enabling researchers to prioritize archiving and preservation efforts.\n",
      "3. **Plagiarism detection**: Designing an AI-powered plagiarism detection system to identify and prevent plagiarism in scientific publications.\n",
      "\n",
      "**Objectives:**\n",
      "\n",
      "1. Develop a cohesive framework that integrates the three AI-driven tools.\n",
      "2. Investigate the role of peer review in ensuring the quality of scientific publications and explore ways to enhance the peer-review process using AI-driven tools.\n",
      "3. Evaluate the effectiveness of the framework in improving the integrity and accessibility of scientific knowledge.\n",
      "\n",
      "**Expected Outcomes:**\n",
      "\n",
      "1. A functional framework that combines AI-driven tools for figure analysis, resource longevity prediction, and plagiarism detection.\n",
      "2. A better understanding of the role of peer review in ensuring the quality of scientific publications.\n",
      "3. Recommendations for enhancing the peer-review process using AI-driven tools.\n",
      "\n",
      "**Methodology:**\n",
      "\n",
      "1. Conduct a thorough review of existing literature on scientific communication, peer review, and AI-driven tools.\n",
      "2. Develop and test the AI-driven tools for figure analysis, resource longevity prediction, and plagiarism detection.\n",
      "3. Integrate the tools into a cohesive framework and evaluate its effectiveness through a pilot study.\n",
      "4. Investigate the role of peer review and explore ways to enhance the process using AI-driven tools.\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "This project addresses a critical issue in scientific communication, ensuring the integrity and accessibility of scientific knowledge. By developing a comprehensive framework that combines AI-driven tools, this project has the potential to advance knowledge and contribute to broader societal goals, such as promoting transparency, accountability, and reproducibility in scientific research.\n",
      "\n",
      "**Rating:** 4.8\n",
      "\n",
      "I made the following changes based on the feedback:\n",
      "\n",
      "1. Clearly defined the project's objectives and expected outcomes.\n",
      "2. Developed a more detailed plan for integrating the various components into a cohesive system.\n",
      "3. Provided a stronger justification for the project's potential to advance knowledge and contribute to broader societal goals.\n",
      "\n",
      "These changes address the reviewer's concerns and strengthen the proposal's fundability.\n",
      "Finished running: rewrite_idea:\n",
      "---ASSESSING FUNDABILITY & IMPACT OF IDEA---\n",
      "Review:\n",
      "\n",
      "The revised research idea, \"Integrating AI-driven Tools for Ensuring the Integrity and Accessibility of Scientific Knowledge,\" demonstrates a clear understanding of the importance of ensuring the integrity and accessibility of scientific knowledge. The proposal effectively addresses the fundability criteria by:\n",
      "\n",
      "1. Proposing high-quality activities that can transform the frontiers of knowledge by integrating AI-driven tools for figure analysis, resource longevity prediction, and plagiarism detection.\n",
      "2. Contributing to broader societal goals, such as promoting transparency, accountability, and reproducibility in scientific research.\n",
      "3. Providing a well-defined plan and rationale, including a clear methodology and expected outcomes.\n",
      "\n",
      "However, some areas for improvement remain:\n",
      "\n",
      "1. The proposal could benefit from a more detailed discussion of the technical approaches and methodologies employed in developing the AI-driven tools.\n",
      "2. While the proposal mentions the importance of peer review, it would be beneficial to further explore the role of AI-driven tools in enhancing the peer-review process.\n",
      "3. The evaluation metrics for the framework's effectiveness could be more explicitly stated.\n",
      "\n",
      "Feedback:\n",
      "\n",
      "To further strengthen the proposal, consider the following suggestions:\n",
      "\n",
      "1. Provide more technical details on the development of the AI-driven tools, including the machine learning algorithms and data sources used.\n",
      "2. Explore the potential of AI-driven tools in enhancing the peer-review process, including the role of AI in identifying biases and improving reviewer performance.\n",
      "3. Clearly define the evaluation metrics for the framework's effectiveness, including both quantitative and qualitative measures.\n",
      "\n",
      "Rating (1-5): 4.5\n",
      "\n",
      "The revised proposal demonstrates significant improvement in addressing the fundability criteria. However, to achieve a perfect score, the proposal could benefit from more detailed technical discussions and a clearer exploration of the role of AI-driven tools in enhancing the peer-review process.\n",
      "Finished running: assess_fundability:\n",
      "---DECIDING ON UPDATE VIA: FUNDABILITY & IMPACT---\n",
      "no_rewrite\n",
      "---ROUTE TO REWRITE---\n",
      "no_rewrite\n",
      "---ROUTE TO FINAL---\n",
      "Finished running: analyze_fundability:\n",
      "NO MORE UPDATES NEEDED\n",
      "Finished running: no_more:\n",
      "---STATE PRINTER---\n",
      "base_idea Idea: After conducting a comprehensive analysis of the abstracts and related work provided, I have formulated a well-formulated idea for a new research paper that logically follows the direction of research in your field. Here's a potential research idea:\n",
      "\n",
      "**Title:** \"Evaluating the Impact of AI-generated Content on the Quality and Integrity of Scientific Publishing: A Large-scale Analysis of Peer-reviewed Articles\"\n",
      "\n",
      "**Research Question:** How do AI-generated content and paraphrased text affect the quality, readability, and credibility of scientific publications, and what are the implications for the scientific community?\n",
      "\n",
      "**Background:** The rapid advancement of AI technology has made text generation tools increasingly accessible, scalable, and effective. However, this poses a significant threat to the credibility of scientific literature, as AI-generated content can be used for plagiarism and manipulation of scientific results. The rise of AI-generated content also raises concerns about the quality and integrity of scientific publishing, particularly in the context of peer review and the dissemination of research findings.\n",
      "\n",
      "**Research Objectives:**\n",
      "\n",
      "1. Develop a large-scale analysis of peer-reviewed articles to identify the prevalence of AI-generated content and paraphrased text in scientific publications.\n",
      "2. Investigate the impact of AI-generated content on the quality, readability, and credibility of scientific publications, using metrics such as clarity, coherence, and accuracy.\n",
      "3. Examine the relationship between AI-generated content and the peer-review process, including the role of author-suggested reviewers and the potential for bias in the review process.\n",
      "4. Explore the implications of AI-generated content for the scientific community, including the potential for misinformation, manipulation, and the erosion of trust in scientific research.\n",
      "\n",
      "**Methodology:**\n",
      "\n",
      "1. Collect a large dataset of peer-reviewed articles from various scientific fields, including but not limited to neuroscience, biology, and computer science.\n",
      "2. Develop and apply natural language processing (NLP) techniques to detect AI-generated content and paraphrased text in the collected dataset.\n",
      "3. Conduct a quantitative analysis of the prevalence and characteristics of AI-generated content in scientific publications, including metrics such as frequency, quality, and readability.\n",
      "4. Investigate the relationship between AI-generated content and the peer-review process, including the role of author-suggested reviewers and the potential for bias in the review process.\n",
      "5. Conduct a qualitative analysis of the implications of AI-generated content for the scientific community, including the potential for misinformation, manipulation, and the erosion of trust in scientific research.\n",
      "\n",
      "**Expected Outcomes:**\n",
      "\n",
      "1. A comprehensive understanding of the prevalence and characteristics of AI-generated content in scientific publications.\n",
      "2. An assessment of the impact of AI-generated content on the quality, readability, and credibility of scientific publications.\n",
      "3. Insights into the relationship between AI-generated content and the peer-review process, including the potential for bias and manipulation.\n",
      "4. Recommendations for the scientific community, publishers, and policymakers to address the challenges and opportunities posed by AI-generated content in scientific publishing.\n",
      "\n",
      "**Significance:** This study will provide valuable insights into the impact of AI-generated content on the quality and integrity of scientific publishing, and will inform strategies for maintaining the credibility and trustworthiness of scientific research in the face of emerging technologies. The findings of this study will have significant implications for the scientific community, publishers, and policymakers, and will contribute to the development of best practices for ensuring the integrity and reliability of scientific research.\n",
      "\n",
      "Final Idea: : Based on the feedback, I propose the following revised research idea:\n",
      "\n",
      "**Title:** Integrating AI-driven Tools for Ensuring the Integrity and Accessibility of Scientific Knowledge\n",
      "\n",
      "**Research Idea:**\n",
      "\n",
      "This project aims to develop a comprehensive framework that combines AI-driven tools for figure analysis, resource longevity prediction, and plagiarism detection to ensure the integrity and accessibility of scientific knowledge. The framework will integrate the following components:\n",
      "\n",
      "1. **AI-driven figure analysis**: Developing a tool that uses machine learning algorithms to analyze and improve the accessibility of figures in scientific publications.\n",
      "2. **Resource longevity prediction**: Creating a predictive model that forecasts the longevity of online resources cited in scientific publications, enabling researchers to prioritize archiving and preservation efforts.\n",
      "3. **Plagiarism detection**: Designing an AI-powered plagiarism detection system to identify and prevent plagiarism in scientific publications.\n",
      "\n",
      "**Objectives:**\n",
      "\n",
      "1. Develop a cohesive framework that integrates the three AI-driven tools.\n",
      "2. Investigate the role of peer review in ensuring the quality of scientific publications and explore ways to enhance the peer-review process using AI-driven tools.\n",
      "3. Evaluate the effectiveness of the framework in improving the integrity and accessibility of scientific knowledge.\n",
      "\n",
      "**Expected Outcomes:**\n",
      "\n",
      "1. A functional framework that combines AI-driven tools for figure analysis, resource longevity prediction, and plagiarism detection.\n",
      "2. A better understanding of the role of peer review in ensuring the quality of scientific publications.\n",
      "3. Recommendations for enhancing the peer-review process using AI-driven tools.\n",
      "\n",
      "**Methodology:**\n",
      "\n",
      "1. Conduct a thorough review of existing literature on scientific communication, peer review, and AI-driven tools.\n",
      "2. Develop and test the AI-driven tools for figure analysis, resource longevity prediction, and plagiarism detection.\n",
      "3. Integrate the tools into a cohesive framework and evaluate its effectiveness through a pilot study.\n",
      "4. Investigate the role of peer review and explore ways to enhance the process using AI-driven tools.\n",
      "\n",
      "**Justification:**\n",
      "\n",
      "This project addresses a critical issue in scientific communication, ensuring the integrity and accessibility of scientific knowledge. By developing a comprehensive framework that combines AI-driven tools, this project has the potential to advance knowledge and contribute to broader societal goals, such as promoting transparency, accountability, and reproducibility in scientific research.\n",
      "\n",
      "**Rating:** 4.8\n",
      "\n",
      "I made the following changes based on the feedback:\n",
      "\n",
      "1. Clearly defined the project's objectives and expected outcomes.\n",
      "2. Developed a more detailed plan for integrating the various components into a cohesive system.\n",
      "3. Provided a stronger justification for the project's potential to advance knowledge and contribute to broader societal goals.\n",
      "\n",
      "These changes address the reviewer's concerns and strengthen the proposal's fundability.\n",
      "\n",
      "Similar (to my own) Papers: None\n",
      "\n",
      "Related (to idea) Papers: None\n",
      "\n",
      "Fundability Feedback: : Review:\n",
      "\n",
      "The revised research idea, \"Integrating AI-driven Tools for Ensuring the Integrity and Accessibility of Scientific Knowledge,\" demonstrates a clear understanding of the importance of ensuring the integrity and accessibility of scientific knowledge. The proposal effectively addresses the fundability criteria by:\n",
      "\n",
      "1. Proposing high-quality activities that can transform the frontiers of knowledge by integrating AI-driven tools for figure analysis, resource longevity prediction, and plagiarism detection.\n",
      "2. Contributing to broader societal goals, such as promoting transparency, accountability, and reproducibility in scientific research.\n",
      "3. Providing a well-defined plan and rationale, including a clear methodology and expected outcomes.\n",
      "\n",
      "However, some areas for improvement remain:\n",
      "\n",
      "1. The proposal could benefit from a more detailed discussion of the technical approaches and methodologies employed in developing the AI-driven tools.\n",
      "2. While the proposal mentions the importance of peer review, it would be beneficial to further explore the role of AI-driven tools in enhancing the peer-review process.\n",
      "3. The evaluation metrics for the framework's effectiveness could be more explicitly stated.\n",
      "\n",
      "Feedback:\n",
      "\n",
      "To further strengthen the proposal, consider the following suggestions:\n",
      "\n",
      "1. Provide more technical details on the development of the AI-driven tools, including the machine learning algorithms and data sources used.\n",
      "2. Explore the potential of AI-driven tools in enhancing the peer-review process, including the role of AI in identifying biases and improving reviewer performance.\n",
      "3. Clearly define the evaluation metrics for the framework's effectiveness, including both quantitative and qualitative measures.\n",
      "\n",
      "Rating (1-5): 4.5\n",
      "\n",
      "The revised proposal demonstrates significant improvement in addressing the fundability criteria. However, to achieve a perfect score, the proposal could benefit from more detailed technical discussions and a clearer exploration of the role of AI-driven tools in enhancing the peer-review process.\n",
      "\n",
      "Num Steps: 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Let's do it with Acuna papers:\n",
    "abstract_1 = \"### PAPER 1: Peer review is an important part of science, aimed at providing expert and objective assess- ment of a manuscript. Because of many factors, including time constraints, unique expertise needs, and deference, many journals ask authors to suggest peer reviewers for their own manuscript. Previous researchers have found differing effects about this practice that might be inconclusive due to sample sizes. In this article, we analyze the association between author-suggested reviewers and review invitation, review scores, acceptance rates, and subjective review quality using a large dataset of close to 8K manuscripts from 46K authors and 21K reviewers from the journal PLOS ONE’s Neuroscience section. We found that all- author-suggested review panels increase the chances of acceptance by 20 percent points vs all-editor-suggested panels while agreeing to review less often. While PLOS ONE has since ended the practice of asking for suggested reviewers, many others still use them and perhaps should consider the results presented here.\"\n",
    "abstract_2 = \"### PAPER 2: Figures are an essential part of scientific communication. Yet little is understood about how accessible (e.g., color-blind safe), readable (e.g., good contrast), and explainable (e.g., contain captions and legends) they are. We develop computational techniques to measure these features and analyze a large sample of them from open access publications. Our method combines computer and human vision research principles, achieving high accuracy in detecting problems. In our sample, we estimated that around 20.6% of publications contain either accessibility, readability, or explainability issues (around 2% of all figures contain accessibility issues, 3% of diagnostic figures contain readability issues, and 23% of line charts contain explainability issues). We release our analysis as a dataset and methods for further examination by the scientific community.\"\n",
    "abstract_3 = \"### PAPER 3: Research has shown that most resources shared in articles (e.g., URLs to code or data) are not kept up to date and mostly disappear from the web after some years (Zeng et al., 2019). Little is known about the factors that differentiate and predict the longevity of these resources. This article explores a range of explanatory features related to the publication venue, authors, references, and where the resource is shared. We analyze an extensive repository of publications and, through web archival services, reconstruct how they looked at different time points. We discover that the most important factors are related to where and how the resource is shared, and surprisingly little is explained by the author’s reputation or prestige of the journal. By examining the places where long-lasting resources are shared, we suggest that it is critical to disseminate and create standards with modern technologies. Finally, we discuss implications for reproducibility and recognizing scientific datasets as first-class citizens.\"\n",
    "abstract_4 = \"### PAPER 4: The rapid advancement of AI technology has made text generation tools like GPT-3 and ChatGPT increasingly accessible, scalable, and effective. This can pose serious threat to the credibility of various forms of media if these technologies are used for plagiarism, including scientific literature and news sources. Despite the development of automated methods for paraphrase identification, detecting this type of plagiarism remains a challenge due to the disparate nature of the datasets on which these methods are trained. In this study, we review traditional and current approaches to paraphrase identification and propose a refined typology of paraphrases. We also investigate how this typology is represented in popular datasets and how under-representation of certain types of paraphrases impacts detection capabilities. Finally, we outline new directions for future research and datasets in the pursuit of more effective paraphrase detection using AI.\"\n",
    "abstracts = [abstract_1, abstract_2, abstract_3, abstract_4]\n",
    "concat = ' '.join(abstracts)\n",
    "\n",
    "inputs = {\"og_papers\": concat, \"num_steps\":0}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        print(f\"Finished running: {key}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb7c641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
